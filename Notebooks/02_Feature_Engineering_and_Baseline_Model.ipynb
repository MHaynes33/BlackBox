{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5016e2-b417-43d0-a62f-af484e5df18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbb8b0-5d07-4974-8347-fb46a60e65a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'combined_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     20\u001b[39m sns.set_theme(style=\u001b[33m\"\u001b[39m\u001b[33mwhitegrid\u001b[39m\u001b[33m\"\u001b[39m, palette=\u001b[33m\"\u001b[39m\u001b[33mcrest\u001b[39m\u001b[33m\"\u001b[39m, font_scale=\u001b[32m1.1\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Step 1: Load Clean Data\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m combined_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcombined_clean.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Clean dataset loaded successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m\"\u001b[39m, combined_df.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'combined_clean.csv'"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ğŸš€ Phase 2 â€“ Feature Engineering & Baseline Models\n",
    "# ==========================================================\n",
    "# Author: Ayushi Bohra\n",
    "# Project: ACME Corp â€“ Legacy Reimbursement System\n",
    "# ==========================================================\n",
    "\n",
    "# Step 0: Import Libraries\n",
    "# ----------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"crest\", font_scale=1.1)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 1: Load Clean Data\n",
    "# ----------------------------------------------------------\n",
    "combined_df = pd.read_csv(\"../data/combined_clean.csv\")\n",
    "print(\"âœ… Clean dataset loaded successfully!\")\n",
    "print(\"Shape:\", combined_df.shape)\n",
    "display(combined_df.head())\n",
    "\n",
    "print(\"\\nğŸ§¾ Missing values per column:\")\n",
    "print(combined_df.isnull().sum())\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 2: Feature Engineering\n",
    "# ----------------------------------------------------------\n",
    "# Derived features based on instructor feedback (Mike Haynes)\n",
    "combined_df[\"cost_per_day\"] = combined_df[\"total_receipts_amount\"] / combined_df[\"trip_duration_days\"].replace(0, np.nan)\n",
    "combined_df[\"cost_per_mile\"] = combined_df[\"total_receipts_amount\"] / combined_df[\"miles_traveled\"].replace(0, np.nan)\n",
    "combined_df[\"miles_per_day\"] = combined_df[\"miles_traveled\"] / combined_df[\"trip_duration_days\"].replace(0, np.nan)\n",
    "combined_df[\"cost_ratio\"] = combined_df[\"cost_per_day\"] / combined_df[\"cost_per_mile\"]\n",
    "\n",
    "# Clean up infinities or missing values\n",
    "combined_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "print(\"\\nâœ… Derived features created and cleaned successfully!\")\n",
    "display(combined_df[[\"cost_per_day\", \"cost_per_mile\", \"miles_per_day\", \"cost_ratio\"]].describe())\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ğŸ§® Step 2.1: IQR-Based Outlier Detection\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\nğŸ“ Applying IQR Outlier Detection...\")\n",
    "\n",
    "def detect_outliers_iqr(df, columns):\n",
    "    outlier_info = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
    "        outlier_info[col] = outliers.shape[0]\n",
    "        print(f\"Outliers detected in {col}: {outliers.shape[0]}\")\n",
    "    return outlier_info\n",
    "\n",
    "numeric_cols = [\"trip_duration_days\", \"miles_traveled\", \"total_receipts_amount\", \n",
    "                \"reimbursement\", \"cost_per_day\", \"cost_per_mile\", \"miles_per_day\", \"cost_ratio\"]\n",
    "\n",
    "iqr_results = detect_outliers_iqr(combined_df, numeric_cols)\n",
    "\n",
    "print(\"\\n Outlier check complete.\")\n",
    "print(\"Summary (count of detected outliers per feature):\")\n",
    "print(iqr_results)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 3: Feature Distributions\n",
    "# ----------------------------------------------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "sns.histplot(combined_df[\"cost_per_day\"], kde=True, ax=axes[0,0], color=\"olive\")\n",
    "sns.histplot(combined_df[\"cost_per_mile\"], kde=True, ax=axes[0,1], color=\"seagreen\")\n",
    "sns.histplot(combined_df[\"miles_per_day\"], kde=True, ax=axes[1,0], color=\"teal\")\n",
    "sns.histplot(combined_df[\"cost_ratio\"], kde=True, ax=axes[1,1], color=\"darkcyan\")\n",
    "axes[0,0].set_title(\"Cost per Day\")\n",
    "axes[0,1].set_title(\"Cost per Mile\")\n",
    "axes[1,0].set_title(\"Miles per Day\")\n",
    "axes[1,1].set_title(\"Cost Ratio\")\n",
    "plt.suptitle(\"ğŸ“Š Distribution of Derived Features\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 4: Prepare Data for Modeling\n",
    "# ----------------------------------------------------------\n",
    "features = [\n",
    "    \"trip_duration_days\",\n",
    "    \"miles_traveled\",\n",
    "    \"total_receipts_amount\",\n",
    "    \"cost_per_day\",\n",
    "    \"cost_per_mile\",\n",
    "    \"miles_per_day\",\n",
    "    \"cost_ratio\"\n",
    "]\n",
    "target = \"reimbursement\"\n",
    "\n",
    "X = combined_df[features]\n",
    "y = combined_df[target]\n",
    "\n",
    "# Manual 75/25 split for train/test\n",
    "split = int(0.75 * len(combined_df))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "print(f\"\\nğŸ“‚ Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 5: Baseline Model â€” Linear Regression\n",
    "# ----------------------------------------------------------\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_lin)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred_lin))\n",
    "r2 = r2_score(y_test, y_pred_lin)\n",
    "\n",
    "print(\"\\nğŸ“Š Baseline Linear Regression Performance:\")\n",
    "print(f\"MAE:  {mae:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"RÂ²:   {r2:.3f}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 6: Ridge & Lasso Regression\n",
    "# ----------------------------------------------------------\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "print(\"\\nğŸ“˜ Ridge Regression RÂ²:\", round(r2_score(y_test, ridge_pred), 3))\n",
    "print(\"ğŸ“— Lasso Regression RÂ²:\", round(r2_score(y_test, lasso_pred), 3))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 7: Polynomial Regression (Degree 2)\n",
    "# ----------------------------------------------------------\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree=2, include_bias=False), LinearRegression())\n",
    "poly_model.fit(X_train, y_train)\n",
    "poly_pred = poly_model.predict(X_test)\n",
    "print(\"ğŸ“™ Polynomial Regression (deg=2) RÂ²:\", round(r2_score(y_test, poly_pred), 3))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 8: Model Comparison Summary\n",
    "# ----------------------------------------------------------\n",
    "Summary = pd.DataFrame({\n",
    "    \"Model\": [\"Linear\", \"Ridge\", \"Lasso\", \"Polynomial (deg=2)\"],\n",
    "    \"RÂ² Score\": [\n",
    "        r2_score(y_test, y_pred_lin),\n",
    "        r2_score(y_test, ridge_pred),\n",
    "        r2_score(y_test, lasso_pred),\n",
    "        r2_score(y_test, poly_pred)\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        sqrt(mean_squared_error(y_test, y_pred_lin)),\n",
    "        sqrt(mean_squared_error(y_test, ridge_pred)),\n",
    "        sqrt(mean_squared_error(y_test, lasso_pred)),\n",
    "        sqrt(mean_squared_error(y_test, poly_pred))\n",
    "    ]\n",
    "})\n",
    "print(\"\\nğŸ“ˆ Model Performance Summary:\")\n",
    "display(summary.style.background_gradient(cmap=\"YlGnBu\").format({\"RÂ² Score\": \"{:.3f}\", \"RMSE\": \"{:.3f}\"}))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 9: Visualize Actual vs Predicted (Best Model)\n",
    "# ----------------------------------------------------------\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(x=y_test, y=poly_pred, color=\"teal\", alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Actual Reimbursement\")\n",
    "plt.ylabel(\"Predicted Reimbursement (Polynomial Model)\")\n",
    "plt.title(\"ğŸ¯ Actual vs Predicted â€” Best Fit Model (Polynomial Regression)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 10: Save Enhanced Dataset\n",
    "# ----------------------------------------------------------\n",
    "combined_df.to_csv(\"phase2_features_baseline_models.csv\", index=False)\n",
    "print(\"\\nğŸ’¾ Saved: phase2_features_baseline_models.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66028ff-0484-4488-9085-fb1c3e623d4a",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "Engineer new derived features based on travel and cost metrics.\n",
    "\n",
    "Build baseline models (Linear, Ridge, Lasso, Polynomial) for performance comparison.\n",
    "\n",
    "Identify key drivers influencing reimbursement outcomes.\n",
    "\n",
    "Ensure data consistency, interpretability, and model explainability.\n",
    "\n",
    "ğŸ§© Step 1: Load Clean Data\n",
    "\n",
    "This section loads the cleaned dataset.\n",
    "It verifies data quality, checks for missing values, and ensures all features are properly formatted before engineering begins.\n",
    "\n",
    "âš™ï¸ Step 2: Feature Engineering\n",
    "\n",
    "Derived features created to capture relationships in travel cost behavior:\n",
    "\n",
    "Cost per Day = total_receipts_amount / trip_duration_days\n",
    "\n",
    "Cost per Mile = total_receipts_amount / miles_traveled\n",
    "\n",
    "Miles per Day = miles_traveled / trip_duration_days\n",
    "\n",
    "Cost Ratio = cost_per_day / cost_per_mile\n",
    "\n",
    "These variables reflect efficiency and expense intensity for each trip, helping replicate hidden business logic from the legacy system.\n",
    "\n",
    "âš™ï¸ Step 2.1: **Observation:**  \n",
    "No extreme outliers were detected using the IQR test, confirming that the dataset is stable and suitable for baseline modeling.\n",
    "\n",
    "ğŸ“Š Step 3: Feature Distributions\n",
    "\n",
    "The histograms illustrate that:\n",
    "\n",
    "Most trips cluster at low or moderate costs.\n",
    "\n",
    "A few longer trips with high receipts cause right-skewed tails.\n",
    "\n",
    "All derived metrics are positive and consistent â€” no missing or invalid values remain.\n",
    "\n",
    "Insight:\n",
    "Cost-related distributions show expected business behavior â€” short trips dominate, while extended ones increase receipts and reimbursement amounts.\n",
    "\n",
    "ğŸ§® Step 4: Data Preparation\n",
    "\n",
    "Selected 7 numerical input features for modeling.\n",
    "\n",
    "Split data into 75% training and 25% testing sets to maintain reproducibility.\n",
    "\n",
    "Ensured no missing or infinite values before model fitting.\n",
    "\n",
    "ğŸ“ˆ Step 5: Baseline Model â€” Linear Regression\n",
    "\n",
    "The Linear Regression model serves as our benchmark.\n",
    "It establishes how well simple linear relationships can explain reimbursement outcomes.\n",
    "\n",
    "Metrics:\n",
    "\n",
    "MAE (Mean Absolute Error)\n",
    "\n",
    "RMSE (Root Mean Squared Error)\n",
    "\n",
    "RÂ² (Goodness of fit)\n",
    "\n",
    "Observation:\n",
    "The baseline performs strongly, showing receipts, miles, and trip duration as key reimbursement predictors.\n",
    "\n",
    "ğŸ§± Step 6: Ridge & Lasso Regression\n",
    "\n",
    "Regularized models (Ridge & Lasso) were added to:\n",
    "\n",
    "Prevent overfitting\n",
    "\n",
    "Improve model generalization\n",
    "\n",
    "Handle correlated variables efficiently.\n",
    "\n",
    "Observation:\n",
    "Both models achieve similar RÂ² values while improving model stability and reducing variance.\n",
    "\n",
    "ğŸ§® Step 7: Polynomial Regression (Degree 2)\n",
    "\n",
    "Introduced polynomial terms to capture nonlinear relationships between:\n",
    "\n",
    "Trip duration Ã— receipts\n",
    "\n",
    "Miles Ã— receipts\n",
    "\n",
    "Cost ratios\n",
    "\n",
    "Observation:\n",
    "Polynomial Regression provides the best RÂ², replicating complex decision behavior in the original legacy logic.\n",
    "\n",
    "ğŸ“˜ Step 8: Model Performance Summary\n",
    "\n",
    "| Model      | RÂ² Score          | RMSE                |\n",
    "| ---------- | ----------------- | ------------------- |\n",
    "| Linear     | Moderate          | Low                 |\n",
    "| Ridge      | Slightly Improved | Stable              |\n",
    "| Lasso      | Similar           | Sparse Coefficients |\n",
    "| Polynomial | **Highest**       | **Best Fit**        |\n",
    "\n",
    "Insight:\n",
    "Polynomial regression yields the best performance, suggesting the legacy system likely applied tiered or nonlinear reimbursement calculations.\n",
    "\n",
    "ğŸ¯ Step 9: Actual vs Predicted (Polynomial Model)\n",
    "\n",
    "A scatter plot compares predicted vs. actual reimbursements.\n",
    "\n",
    "Points align close to the diagonal â€” showing accurate predictions.\n",
    "\n",
    "Slight deviation in high reimbursements reflects rare, high-cost business trips.\n",
    "\n",
    "Conclusion:\n",
    "The model successfully explains both regular and edge-case reimbursements.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
